{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc61b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('BERT4Rec-VAE-Pytorch')\n",
    "\n",
    "from models.bert import BERTModel\n",
    "from models.bert_modules.bert import BERT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31eb8e",
   "metadata": {},
   "source": [
    "### Service functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d527e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_seq(seq, max_length, end_code):\n",
    "  \n",
    "  if len(seq) >= max_length:\n",
    "    return seq[:max_length]\n",
    "  else:\n",
    "    return (max_length - len(seq)) * [end_code] + seq\n",
    "\n",
    "def recall_k(y_pred, y_true, k=10):\n",
    "    \n",
    "    top_k = torch.topk(y_pred, k).indices.tolist()\n",
    "    result = [el[0] in el[1] for el in zip(y_true.tolist(), top_k)]\n",
    "    \n",
    "    return np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a1d41",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e92e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_csv('ml-1m/ratings.dat', \n",
    "                    sep='::',\n",
    "                    header=None,\n",
    "                    index_col=0,\n",
    "                    names=['user_id', 'movie_id', 'rating', 'ts'], \n",
    "                    engine='python')\n",
    "          .reset_index(drop=False)\n",
    "       )\n",
    "\n",
    "sequences = data.sort_values(by=['user_id', 'ts']).groupby('user_id')['movie_id'].agg(lambda x: list(x)).to_dict()\n",
    "sequences = {u: s for u, s in sequences.items() if len(s) > 0}\n",
    "\n",
    "mask_code = 0\n",
    "max_len = 100\n",
    "end_code = data['movie_id'].max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c339e",
   "metadata": {},
   "source": [
    "### Train / Valid / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264d37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = defaultdict(list)\n",
    "val = {}\n",
    "test = {}\n",
    "\n",
    "for user, sequence in sequences.items():\n",
    "\n",
    "    train[user] = equalize_seq(sequence[:-1], max_length=max_len, end_code=end_code)\n",
    "\n",
    "    if np.random.choice([0, 1]):\n",
    "        val[user] = equalize_seq(sequence, max_length=max_len, end_code=end_code)\n",
    "      \n",
    "    else:\n",
    "        test[user] = equalize_seq(sequence, max_length=max_len, end_code=end_code)\n",
    "\n",
    "test_indexes = np.array(test.keys())\n",
    "val_indexes = np.array(val.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87a7c2",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69104f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BertConf:\n",
    "    bert_max_len: int\n",
    "    num_items: int\n",
    "    bert_num_blocks: int\n",
    "    bert_num_heads: int\n",
    "    bert_hidden_units: int\n",
    "    bert_dropout: float = 0.1\n",
    "    model_init_seed: int = 42\n",
    "\n",
    "conf = BertConf(bert_max_len=max_len, \n",
    "                num_items=end_code + 1, \n",
    "                bert_num_blocks=2, \n",
    "                bert_num_heads=2, \n",
    "                bert_hidden_units=100)\n",
    "\n",
    "model = BERTModel(conf).to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0526ece",
   "metadata": {},
   "source": [
    "### Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bf38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TrainMaskedDataset(Dataset):\n",
    "    def __init__(self, data, end_code=-1, p=0.2):\n",
    "        self.data = data\n",
    "        self.p = p\n",
    "        self.end_code=end_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get X and y from the initial dataset\n",
    "\n",
    "        batch = self.data[index]\n",
    "        mask = torch.bernoulli(batch, p=self.p)\n",
    "\n",
    "        # Create train\n",
    "        X = batch * (1 - mask)\n",
    "\n",
    "        # Create target\n",
    "        y = batch * mask\n",
    "        y[mask == 0] = self.end_code\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "class ValidMaskedDataset(Dataset):\n",
    "    def __init__(self, data, end_code):\n",
    "        self.data = data\n",
    "        self.end_code=end_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get X and y from the initial dataset\n",
    "\n",
    "        batch = self.data[index]\n",
    "        mask = torch.zeros(batch.size())\n",
    "        mask[-1] = 1\n",
    "\n",
    "        # Create train\n",
    "        X = batch * (1 - mask)\n",
    "\n",
    "        # Create target\n",
    "        y = batch[-1]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ca798",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ac1ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.081 6.1798 6.5893\n",
      "1000 0.121 5.7555 6.1733\n",
      "1500 0.157 5.4007 6.0148\n",
      "2000 0.167 5.406 5.9092\n",
      "2500 0.19 5.2223 5.8031\n",
      "3000 0.2 5.1434 5.788\n",
      "3500 0.204 5.1916 5.7396\n",
      "4000 0.193 5.0306 5.739\n",
      "4500 0.215 4.9869 5.6909\n",
      "5000 0.209 5.113 5.6814\n",
      "5500 0.208 4.9688 5.6987\n",
      "6000 0.213 4.9893 5.653\n",
      "6500 0.223 4.9258 5.6269\n",
      "7000 0.222 4.8817 5.6322\n",
      "7500 0.229 4.9849 5.5975\n",
      "8000 0.223 4.8508 5.5905\n",
      "8500 0.241 4.8254 5.568\n",
      "9000 0.24 4.9057 5.5633\n",
      "9500 0.243 4.7904 5.5364\n",
      "10000 0.234 4.8733 5.6357\n",
      "10500 0.24 4.8073 5.5718\n",
      "11000 0.243 4.8046 5.5552\n",
      "11500 0.236 4.8089 5.5365\n",
      "12000 0.255 4.7918 5.5217\n",
      "12500 0.246 4.8708 5.554\n",
      "13000 0.245 4.7596 5.5305\n"
     ]
    }
   ],
   "source": [
    "dataset = TrainMaskedDataset(torch.tensor(list(train.values())), end_code)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "val_dataset = ValidMaskedDataset(torch.tensor(list(val.values())), end_code)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=end_code, reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 5000\n",
    "outputs = []\n",
    "losses = []\n",
    "\n",
    "counter = 0\n",
    "recall_list = []\n",
    "for epoch in range(epochs):\n",
    "    for X, y in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to('cuda:0')\n",
    "        y = y.to('cuda:0')\n",
    "\n",
    "        loss = loss_function(model.forward(X).view(-1, 3955), y.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "         \n",
    "        optimizer.step()\n",
    "        \n",
    "        counter += 1\n",
    "        if counter % 500 == 0:\n",
    "            val_losses = []\n",
    "            recall_batch = []\n",
    "            for X_val, y_val in val_loader:\n",
    "                \n",
    "                X_val = X_val.to('cuda:0')\n",
    "                y_val = y_val.to('cuda:0')\n",
    "                \n",
    "                y_pred = model.forward(X_val.long())[:, -1, :]\n",
    "                \n",
    "                val_loss = loss_function(y_pred.view(-1, 3955), y_val.long().view(-1))\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                recall_batch.append(recall_k(y_pred, y_val, k=10))\n",
    "\n",
    "            print(counter, np.mean(recall_batch).round(3), np.round(loss.item(), 4), np.mean(val_losses).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc1034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
