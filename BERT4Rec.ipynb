{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc61b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchmetrics.functional import retrieval_normalized_dcg\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('BERT4Rec-VAE-Pytorch')\n",
    "\n",
    "from models.bert import BERTModel\n",
    "from models.bert_modules.bert import BERT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31eb8e",
   "metadata": {},
   "source": [
    "### Service functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50d527e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_seq(seq, max_length, end_code):\n",
    "  \n",
    "  if len(seq) >= max_length:\n",
    "    return seq[:max_length]\n",
    "  else:\n",
    "    return (max_length - len(seq)) * [end_code] + seq\n",
    "\n",
    "\n",
    "def recall_k(y_pred, y_true, k=10):\n",
    "    \n",
    "    top_k = torch.topk(y_pred, k).indices.tolist()\n",
    "    result = [el[0] in el[1] for el in zip(y_true.tolist(), top_k)]\n",
    "    \n",
    "    return np.mean(result)\n",
    "\n",
    "\n",
    "def ndcg_k(y_pred, y_true, k=10):\n",
    "    \n",
    "    top_k = torch.topk(y_pred, k).indices.tolist()\n",
    "    results = []\n",
    "    for true_label, preds in zip(y_true.tolist(), top_k):\n",
    "        tl = [[el == true_label for el in preds]]\n",
    "        preds = [[1 for _ in preds]]\n",
    "        results.append(ndcg_score(tl, preds))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a1d41",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e92e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_csv('ml-1m/ratings.dat', \n",
    "                    sep='::',\n",
    "                    header=None,\n",
    "                    index_col=0,\n",
    "                    names=['user_id', 'movie_id', 'rating', 'ts'], \n",
    "                    engine='python')\n",
    "          .reset_index(drop=False)\n",
    "       )\n",
    "\n",
    "sequences = data.sort_values(by=['user_id', 'ts']).groupby('user_id')['movie_id'].agg(lambda x: list(x)).to_dict()\n",
    "sequences = {u: s for u, s in sequences.items() if len(s) > 0}\n",
    "\n",
    "mask_code = 0\n",
    "max_len = 100\n",
    "end_code = data['movie_id'].max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c339e",
   "metadata": {},
   "source": [
    "### Train / Valid / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264d37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = defaultdict(list)\n",
    "val = {}\n",
    "test = {}\n",
    "\n",
    "for user, sequence in sequences.items():\n",
    "\n",
    "    train[user] = equalize_seq(sequence[:-1], max_length=max_len, end_code=end_code)\n",
    "\n",
    "    if np.random.choice([0, 1]):\n",
    "        val[user] = equalize_seq(sequence, max_length=max_len, end_code=end_code)\n",
    "      \n",
    "    else:\n",
    "        test[user] = equalize_seq(sequence, max_length=max_len, end_code=end_code)\n",
    "\n",
    "test_indexes = np.array(test.keys())\n",
    "val_indexes = np.array(val.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87a7c2",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69104f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BertConf:\n",
    "    bert_max_len: int\n",
    "    num_items: int\n",
    "    bert_num_blocks: int\n",
    "    bert_num_heads: int\n",
    "    bert_hidden_units: int\n",
    "    bert_dropout: float = 0.1\n",
    "    model_init_seed: int = 42\n",
    "\n",
    "conf = BertConf(bert_max_len=max_len, \n",
    "                num_items=end_code + 1, \n",
    "                bert_num_blocks=2, \n",
    "                bert_num_heads=2, \n",
    "                bert_hidden_units=100)\n",
    "\n",
    "model = BERTModel(conf).to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0526ece",
   "metadata": {},
   "source": [
    "### Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bf38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TrainMaskedDataset(Dataset):\n",
    "    def __init__(self, data, end_code=-1, p=0.2):\n",
    "        self.data = data\n",
    "        self.p = p\n",
    "        self.end_code=end_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get X and y from the initial dataset\n",
    "\n",
    "        batch = self.data[index]\n",
    "        mask = torch.bernoulli(batch, p=self.p)\n",
    "\n",
    "        # Create train\n",
    "        X = batch * (1 - mask)\n",
    "\n",
    "        # Create target\n",
    "        y = batch * mask\n",
    "        y[mask == 0] = self.end_code\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "class ValidMaskedDataset(Dataset):\n",
    "    def __init__(self, data, end_code):\n",
    "        self.data = data\n",
    "        self.end_code=end_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get X and y from the initial dataset\n",
    "\n",
    "        batch = self.data[index]\n",
    "        mask = torch.zeros(batch.size())\n",
    "        mask[-1] = 1\n",
    "\n",
    "        # Create train\n",
    "        X = batch * (1 - mask)\n",
    "\n",
    "        # Create target\n",
    "        y = batch[-1]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ca798",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d61ac1ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  500\n",
      "Recall@10:  0.196\n",
      "NDCG:  0.089\n",
      "Train Loss:  5.1276\n",
      "Val Loss:  [5.8991 5.6554 5.6385 5.6334 5.8616 5.9044 5.7201 5.6048 5.6758 5.6505\n",
      " 5.6554 5.759 ]\n",
      "Epoch:  1000\n",
      "Recall@10:  0.21\n",
      "NDCG:  0.095\n",
      "Train Loss:  5.14\n",
      "Val Loss:  [5.8888 5.6883 5.632  5.4712 5.7263 5.6678 5.8513 5.6294 5.7817 5.6129\n",
      " 5.9256 5.472 ]\n",
      "Epoch:  1500\n",
      "Recall@10:  0.202\n",
      "NDCG:  0.092\n",
      "Train Loss:  5.0753\n",
      "Val Loss:  [5.6284 5.538  5.9565 5.9021 5.668  5.6578 5.5701 5.6828 5.5238 5.843\n",
      " 5.5752 5.732 ]\n",
      "Epoch:  2000\n",
      "Recall@10:  0.207\n",
      "NDCG:  0.094\n",
      "Train Loss:  5.0895\n",
      "Val Loss:  [5.7912 5.6837 5.4592 5.8386 5.5511 5.8855 5.6846 5.5114 5.7323 5.7106\n",
      " 5.5943 5.4645]\n",
      "Epoch:  2500\n",
      "Recall@10:  0.211\n",
      "NDCG:  0.096\n",
      "Train Loss:  4.9945\n",
      "Val Loss:  [5.5091 5.7889 5.6641 5.7618 5.754  5.7075 5.5055 5.4691 5.762  5.7103\n",
      " 5.6864 5.5916]\n",
      "Epoch:  4000\n",
      "Recall@10:  0.238\n",
      "NDCG:  0.108\n",
      "Train Loss:  4.9754\n",
      "Val Loss:  [5.5326 5.4327 5.6186 5.6032 5.701  5.5467 5.6744 5.6192 5.7823 5.5463\n",
      " 5.5649 5.5045]\n",
      "Epoch:  4500\n",
      "Recall@10:  0.22\n",
      "NDCG:  0.1\n",
      "Train Loss:  4.8786\n",
      "Val Loss:  [5.4998 5.9357 5.5883 5.6194 5.6274 5.6037 5.6805 5.7207 5.5415 5.4948\n",
      " 5.8509 5.3906]\n",
      "Epoch:  5000\n",
      "Recall@10:  0.228\n",
      "NDCG:  0.104\n",
      "Train Loss:  4.9091\n",
      "Val Loss:  [5.4994 5.5065 5.5916 5.6956 5.6702 5.6365 5.4678 5.5642 5.6547 5.5992\n",
      " 5.7049 5.7193]\n",
      "Epoch:  5500\n",
      "Recall@10:  0.224\n",
      "NDCG:  0.102\n",
      "Train Loss:  4.844\n",
      "Val Loss:  [5.8151 5.5066 5.6838 5.6016 5.6325 5.6667 5.322  5.5106 5.6063 5.5943\n",
      " 5.7466 5.6247]\n",
      "Epoch:  6000\n",
      "Recall@10:  0.23\n",
      "NDCG:  0.105\n",
      "Train Loss:  4.8512\n",
      "Val Loss:  [5.4148 5.4918 5.7746 5.5711 5.454  5.4742 5.5957 5.6584 5.8181 5.5794\n",
      " 5.3968 5.6888]\n",
      "Epoch:  6500\n",
      "Recall@10:  0.232\n",
      "NDCG:  0.106\n",
      "Train Loss:  4.872\n",
      "Val Loss:  [5.499  5.619  5.3587 5.7532 5.3782 5.3214 5.7319 5.5616 5.8078 5.5266\n",
      " 5.663  6.0397]\n",
      "Epoch:  7000\n",
      "Recall@10:  0.231\n",
      "NDCG:  0.105\n",
      "Train Loss:  4.8307\n",
      "Val Loss:  [5.6346 5.4092 5.5942 5.5735 5.53   5.6235 5.6428 5.6731 5.5337 5.601\n",
      " 5.6654 5.6233]\n",
      "Epoch:  7500\n",
      "Recall@10:  0.249\n",
      "NDCG:  0.113\n",
      "Train Loss:  4.8417\n",
      "Val Loss:  [5.8728 5.4736 5.4148 5.6487 5.8421 5.4589 5.2764 5.4111 5.605  5.503\n",
      " 5.5499 5.5604]\n",
      "Epoch:  8000\n",
      "Recall@10:  0.239\n",
      "NDCG:  0.109\n",
      "Train Loss:  4.8418\n",
      "Val Loss:  [5.5295 5.4967 5.6502 5.5816 5.5226 5.6987 5.6026 5.3539 5.6269 5.2848\n",
      " 5.7146 5.6093]\n",
      "Epoch:  8500\n",
      "Recall@10:  0.246\n",
      "NDCG:  0.112\n",
      "Train Loss:  4.7655\n",
      "Val Loss:  [5.7793 5.492  5.7136 5.361  5.597  5.2649 5.4776 5.576  5.6253 5.3901\n",
      " 5.5921 5.4535]\n",
      "Epoch:  9000\n",
      "Recall@10:  0.248\n",
      "NDCG:  0.113\n",
      "Train Loss:  4.8605\n",
      "Val Loss:  [5.463  5.5617 5.7718 5.4899 5.3778 5.5279 5.3459 5.6989 5.6248 5.3839\n",
      " 5.744  5.4602]\n",
      "Epoch:  9500\n",
      "Recall@10:  0.246\n",
      "NDCG:  0.112\n",
      "Train Loss:  4.8022\n",
      "Val Loss:  [5.2529 5.5632 5.3151 5.5116 5.5796 5.5765 5.5759 5.4053 5.3158 5.6579\n",
      " 5.7911 5.7833]\n",
      "Epoch:  10000\n",
      "Recall@10:  0.244\n",
      "NDCG:  0.111\n",
      "Train Loss:  4.6646\n",
      "Val Loss:  [5.4262 5.4364 5.7987 5.3971 5.5614 5.3358 5.4107 5.8899 5.5584 5.4441\n",
      " 5.5389 5.4509]\n",
      "Epoch:  10500\n",
      "Recall@10:  0.247\n",
      "NDCG:  0.112\n",
      "Train Loss:  4.714\n",
      "Val Loss:  [5.799  5.3857 5.7122 5.5439 5.3314 5.3296 5.4749 5.4922 5.764  5.7698\n",
      " 5.6126 5.5134]\n",
      "Epoch:  11000\n",
      "Recall@10:  0.239\n",
      "NDCG:  0.109\n",
      "Train Loss:  4.6909\n",
      "Val Loss:  [5.1135 5.8033 5.5488 5.6005 5.8146 5.4815 5.5755 5.5261 5.5742 5.6043\n",
      " 5.4273 5.6454]\n",
      "Epoch:  11500\n",
      "Recall@10:  0.256\n",
      "NDCG:  0.116\n",
      "Train Loss:  4.7748\n",
      "Val Loss:  [5.5632 5.6909 5.6572 5.6143 5.4655 5.5498 5.5392 5.441  5.5211 5.1248\n",
      " 5.485  5.4491]\n",
      "Epoch:  12000\n",
      "Recall@10:  0.248\n",
      "NDCG:  0.113\n",
      "Train Loss:  4.7221\n",
      "Val Loss:  [5.9162 5.4815 5.6445 5.5789 5.4459 5.6245 5.3096 5.297  5.4205 5.6061\n",
      " 5.3732 5.7875]\n",
      "Epoch:  12500\n",
      "Recall@10:  0.257\n",
      "NDCG:  0.117\n",
      "Train Loss:  4.6868\n",
      "Val Loss:  [5.4796 5.4538 5.6257 5.5754 5.3904 5.6917 5.6766 5.7414 5.5264 5.5064\n",
      " 5.3587 5.2622]\n",
      "Epoch:  13000\n",
      "Recall@10:  0.262\n",
      "NDCG:  0.119\n",
      "Train Loss:  4.613\n",
      "Val Loss:  [5.4784 5.6728 5.4414 5.4887 5.3828 5.4446 5.3681 5.4409 5.5764 5.545\n",
      " 5.5822 5.6932]\n",
      "Epoch:  13500\n",
      "Recall@10:  0.257\n",
      "NDCG:  0.117\n",
      "Train Loss:  4.625\n",
      "Val Loss:  [5.3191 5.4953 5.5395 5.6176 5.516  5.7367 5.3336 5.5055 5.506  5.5765\n",
      " 5.5762 5.3924]\n",
      "Epoch:  14000\n",
      "Recall@10:  0.266\n",
      "NDCG:  0.121\n",
      "Train Loss:  4.708\n",
      "Val Loss:  [5.3373 5.3373 5.6008 5.6253 5.542  5.2059 5.4786 5.5173 5.6409 5.4466\n",
      " 5.7249 5.4386]\n",
      "Epoch:  14500\n",
      "Recall@10:  0.269\n",
      "NDCG:  0.122\n",
      "Train Loss:  4.757\n",
      "Val Loss:  [5.4209 5.3201 5.1962 5.6305 5.274  5.4676 5.6007 5.5716 5.5989 5.4215\n",
      " 5.5234 5.6222]\n",
      "Epoch:  15000\n",
      "Recall@10:  0.265\n",
      "NDCG:  0.121\n",
      "Train Loss:  4.611\n",
      "Val Loss:  [5.454  5.7692 5.4987 5.4017 5.2735 5.3947 5.4468 5.5818 5.429  5.4988\n",
      " 5.5314 5.5559]\n",
      "Epoch:  15500\n",
      "Recall@10:  0.267\n",
      "NDCG:  0.121\n",
      "Train Loss:  4.759\n",
      "Val Loss:  [5.4173 5.6001 5.5458 5.1713 5.5711 5.2545 5.419  5.6677 5.6612 5.5164\n",
      " 5.4785 5.553 ]\n",
      "Epoch:  16000\n",
      "Recall@10:  0.262\n",
      "NDCG:  0.119\n",
      "Train Loss:  4.7638\n",
      "Val Loss:  [5.4014 5.5598 5.3946 5.6943 5.5823 5.5018 5.2385 5.4474 5.6105 5.4929\n",
      " 5.45   5.5986]\n",
      "Epoch:  16500\n",
      "Recall@10:  0.265\n",
      "NDCG:  0.12\n",
      "Train Loss:  4.6406\n",
      "Val Loss:  [5.4487 5.5121 5.4437 5.3867 5.5851 5.5002 5.3803 5.223  5.3854 5.9436\n",
      " 5.5125 5.2985]\n",
      "Epoch:  17000\n",
      "Recall@10:  0.274\n",
      "NDCG:  0.125\n",
      "Train Loss:  4.6544\n",
      "Val Loss:  [5.5047 5.5777 5.4445 5.1683 5.1192 5.3308 5.8821 5.682  5.4156 5.5421\n",
      " 5.4975 5.414 ]\n",
      "Epoch:  17500\n",
      "Recall@10:  0.263\n",
      "NDCG:  0.12\n",
      "Train Loss:  4.6881\n",
      "Val Loss:  [5.3214 5.4718 5.605  5.5368 5.4965 5.3968 5.6052 5.705  5.4464 5.5343\n",
      " 5.3362 5.5642]\n",
      "Epoch:  18000\n",
      "Recall@10:  0.267\n",
      "NDCG:  0.121\n",
      "Train Loss:  4.5979\n",
      "Val Loss:  [5.2258 5.5491 5.5142 5.5726 5.6926 5.3662 5.6091 5.2072 5.4746 5.4327\n",
      " 5.6849 5.4181]\n",
      "Epoch:  18500\n",
      "Recall@10:  0.277\n",
      "NDCG:  0.126\n",
      "Train Loss:  4.5816\n",
      "Val Loss:  [5.8245 5.4428 5.693  5.4067 5.2392 5.6387 5.3376 5.5977 5.3513 5.2948\n",
      " 5.3989 5.3404]\n",
      "Epoch:  19000\n",
      "Recall@10:  0.269\n",
      "NDCG:  0.122\n",
      "Train Loss:  4.7074\n",
      "Val Loss:  [5.5622 5.6501 5.3431 5.5409 5.645  5.4498 5.5006 5.5862 5.4501 5.3632\n",
      " 5.4624 5.2714]\n",
      "Epoch:  19500\n",
      "Recall@10:  0.271\n",
      "NDCG:  0.123\n",
      "Train Loss:  4.6308\n",
      "Val Loss:  [5.4158 5.3648 5.5071 5.5276 5.3923 5.2769 5.5308 5.5373 5.4523 5.5682\n",
      " 5.2438 5.6422]\n",
      "Epoch:  20000\n",
      "Recall@10:  0.273\n",
      "NDCG:  0.124\n",
      "Train Loss:  4.6415\n",
      "Val Loss:  [5.4419 5.6206 5.4495 5.4375 5.36   5.7627 5.6285 5.639  5.5836 5.264\n",
      " 5.3435 5.4716]\n",
      "Epoch:  20500\n",
      "Recall@10:  0.267\n",
      "NDCG:  0.121\n",
      "Train Loss:  4.6164\n",
      "Val Loss:  [5.367  5.5418 5.2983 5.3899 5.4591 5.4998 5.5044 5.5659 5.6634 5.7231\n",
      " 5.4467 5.365 ]\n",
      "Epoch:  21000\n",
      "Recall@10:  0.272\n",
      "NDCG:  0.123\n",
      "Train Loss:  4.6365\n",
      "Val Loss:  [5.787  5.4121 5.4151 5.3728 5.7103 5.4983 5.4028 5.4842 5.7273 5.2039\n",
      " 5.5012 5.3249]\n",
      "Epoch:  21500\n",
      "Recall@10:  0.264\n",
      "NDCG:  0.12\n",
      "Train Loss:  4.5335\n",
      "Val Loss:  [5.2779 5.6284 5.3109 5.8333 5.4158 5.217  5.3509 5.5849 5.303  5.6091\n",
      " 5.3276 5.8016]\n",
      "Epoch:  22000\n",
      "Recall@10:  0.281\n",
      "NDCG:  0.128\n",
      "Train Loss:  4.6684\n",
      "Val Loss:  [5.6658 5.4335 5.6104 5.424  5.3926 5.5678 5.3089 5.2667 5.5722 5.2865\n",
      " 5.5628 5.6371]\n",
      "Epoch:  22500\n",
      "Recall@10:  0.268\n",
      "NDCG:  0.122\n",
      "Train Loss:  4.6058\n",
      "Val Loss:  [5.5358 5.5903 5.5502 5.6088 5.1257 5.6446 5.5304 5.5617 5.5524 5.229\n",
      " 5.4219 5.5356]\n",
      "Epoch:  23000\n",
      "Recall@10:  0.269\n",
      "NDCG:  0.122\n",
      "Train Loss:  4.544\n",
      "Val Loss:  [5.4515 5.311  5.3335 5.4194 5.702  5.5583 5.4407 5.235  5.4453 5.5487\n",
      " 5.4724 5.5873]\n",
      "Epoch:  23500\n",
      "Recall@10:  0.281\n",
      "NDCG:  0.128\n",
      "Train Loss:  4.6091\n",
      "Val Loss:  [5.249  5.5998 5.3357 5.4418 5.2228 5.4953 5.8555 5.4744 5.3109 5.3823\n",
      " 5.3077 5.5602]\n",
      "Epoch:  24000\n",
      "Recall@10:  0.274\n",
      "NDCG:  0.125\n",
      "Train Loss:  4.5158\n",
      "Val Loss:  [5.5015 5.498  5.3667 5.4132 5.337  5.4632 5.5263 5.614  5.3748 5.3387\n",
      " 5.6651 5.4412]\n",
      "Epoch:  24500\n",
      "Recall@10:  0.274\n",
      "NDCG:  0.124\n",
      "Train Loss:  4.6131\n",
      "Val Loss:  [5.7247 5.6317 5.4527 5.4949 5.7474 5.076  5.283  5.4694 5.6939 5.4271\n",
      " 5.275  5.3938]\n",
      "Epoch:  25000\n",
      "Recall@10:  0.278\n",
      "NDCG:  0.126\n",
      "Train Loss:  4.6243\n",
      "Val Loss:  [5.4258 5.4737 5.386  5.545  5.1959 5.4271 5.6196 5.4592 5.3483 5.5106\n",
      " 5.3145 5.4783]\n",
      "Epoch:  25500\n",
      "Recall@10:  0.266\n",
      "NDCG:  0.121\n",
      "Train Loss:  4.5342\n",
      "Val Loss:  [5.3776 5.3241 5.5073 5.2464 5.5313 5.6352 5.4642 5.4751 5.4354 5.4113\n",
      " 5.7682 5.1871]\n",
      "Epoch:  26000\n",
      "Recall@10:  0.278\n",
      "NDCG:  0.126\n",
      "Train Loss:  4.5811\n",
      "Val Loss:  [5.4488 5.5236 5.2599 5.5001 5.2815 5.7265 5.3412 5.2444 5.5929 5.7762\n",
      " 5.3608 5.2374]\n",
      "Epoch:  26500\n",
      "Recall@10:  0.274\n",
      "NDCG:  0.125\n",
      "Train Loss:  4.5457\n",
      "Val Loss:  [5.3889 5.4387 5.5204 5.4452 5.6612 5.3298 5.3528 5.3666 5.4849 5.4798\n",
      " 5.3718 5.3521]\n",
      "Epoch:  27000\n",
      "Recall@10:  0.288\n",
      "NDCG:  0.131\n",
      "Train Loss:  4.4701\n",
      "Val Loss:  [5.2968 5.5762 5.3875 5.5641 5.2217 5.477  5.4285 5.4049 5.7823 5.1801\n",
      " 5.4555 5.3181]\n",
      "Epoch:  27500\n",
      "Recall@10:  0.271\n",
      "NDCG:  0.123\n",
      "Train Loss:  4.5447\n",
      "Val Loss:  [5.4394 5.2151 5.4657 5.3545 5.3552 5.3828 5.4842 5.6663 5.5876 5.4753\n",
      " 5.5467 5.2429]\n",
      "Epoch:  28000\n",
      "Recall@10:  0.273\n",
      "NDCG:  0.124\n",
      "Train Loss:  4.5524\n",
      "Val Loss:  [5.3294 5.24   5.4158 5.6288 5.4107 5.5278 5.6301 5.5136 5.5145 5.4072\n",
      " 5.6045 5.2945]\n",
      "Epoch:  28500\n",
      "Recall@10:  0.278\n",
      "NDCG:  0.126\n",
      "Train Loss:  4.5576\n",
      "Val Loss:  [5.4108 5.3271 5.4891 5.3721 5.3346 5.48   5.6793 5.3818 5.0991 5.4504\n",
      " 5.6186 5.9437]\n",
      "Epoch:  29000\n",
      "Recall@10:  0.27\n",
      "NDCG:  0.123\n",
      "Train Loss:  4.5639\n",
      "Val Loss:  [5.3289 5.3948 5.286  5.3056 5.5206 5.3873 5.5994 5.395  5.2723 5.3638\n",
      " 5.6881 5.7037]\n",
      "Epoch:  29500\n",
      "Recall@10:  0.278\n",
      "NDCG:  0.126\n",
      "Train Loss:  4.5496\n",
      "Val Loss:  [5.4272 5.3258 5.447  5.458  5.3078 5.7231 5.4629 5.4263 5.3488 5.45\n",
      " 5.2697 5.5701]\n",
      "Epoch:  30000\n",
      "Recall@10:  0.291\n",
      "NDCG:  0.132\n",
      "Train Loss:  4.5056\n",
      "Val Loss:  [5.4328 5.8133 5.5993 5.2472 5.4253 5.3523 5.569  5.1991 5.2861 5.3939\n",
      " 5.3439 4.9613]\n",
      "Epoch:  30500\n",
      "Recall@10:  0.28\n",
      "NDCG:  0.127\n",
      "Train Loss:  4.5263\n",
      "Val Loss:  [5.6103 5.3873 5.2759 5.5844 5.591  5.1856 5.4719 5.5002 5.2812 5.3444\n",
      " 5.4869 5.636 ]\n",
      "Epoch:  31000\n",
      "Recall@10:  0.293\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.6001\n",
      "Val Loss:  [5.5312 5.4399 5.5857 5.3089 5.3918 5.4862 5.4385 5.2014 5.6401 5.4879\n",
      " 5.3918 5.3407]\n",
      "Epoch:  31500\n",
      "Recall@10:  0.283\n",
      "NDCG:  0.128\n",
      "Train Loss:  4.5665\n",
      "Val Loss:  [5.4351 5.238  5.3674 5.4093 5.5739 5.6593 5.2599 5.3784 5.2633 5.4559\n",
      " 5.5502 5.2796]\n",
      "Epoch:  32000\n",
      "Recall@10:  0.281\n",
      "NDCG:  0.128\n",
      "Train Loss:  4.4842\n",
      "Val Loss:  [5.3223 5.23   5.3996 5.1989 5.4752 5.1374 5.6344 5.455  5.594  5.4265\n",
      " 5.6563 5.5268]\n",
      "Epoch:  32500\n",
      "Recall@10:  0.294\n",
      "NDCG:  0.134\n",
      "Train Loss:  4.5535\n",
      "Val Loss:  [5.3542 5.4098 5.5485 5.3911 5.3793 5.3918 5.3934 5.4276 5.5211 5.5515\n",
      " 5.3023 5.1065]\n",
      "Epoch:  33000\n",
      "Recall@10:  0.295\n",
      "NDCG:  0.134\n",
      "Train Loss:  4.5434\n",
      "Val Loss:  [5.409  5.3786 5.292  5.6359 5.3706 5.4963 5.184  5.5541 5.3405 5.5432\n",
      " 5.2761 5.441 ]\n",
      "Epoch:  33500\n",
      "Recall@10:  0.283\n",
      "NDCG:  0.129\n",
      "Train Loss:  4.5502\n",
      "Val Loss:  [5.3033 5.6376 5.3135 5.5042 5.3962 5.5653 5.4161 5.3316 5.3498 5.0935\n",
      " 5.5189 5.4788]\n",
      "Epoch:  34000\n",
      "Recall@10:  0.289\n",
      "NDCG:  0.131\n",
      "Train Loss:  4.6218\n",
      "Val Loss:  [5.5476 5.243  5.3654 5.4907 5.5002 5.5184 5.5066 5.4734 5.2818 5.6647\n",
      " 5.3277 5.3544]\n",
      "Epoch:  34500\n",
      "Recall@10:  0.279\n",
      "NDCG:  0.127\n",
      "Train Loss:  4.5616\n",
      "Val Loss:  [5.1676 5.7428 5.5655 5.5276 5.2435 5.6011 5.5434 5.3001 5.1584 5.3064\n",
      " 5.4682 5.5672]\n",
      "Epoch:  35000\n",
      "Recall@10:  0.292\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.6082\n",
      "Val Loss:  [5.3751 5.5247 5.4242 5.2788 5.6333 5.2232 5.1966 5.4883 5.3646 5.6796\n",
      " 5.3902 5.5405]\n",
      "Epoch:  35500\n",
      "Recall@10:  0.283\n",
      "NDCG:  0.129\n",
      "Train Loss:  4.5895\n",
      "Val Loss:  [5.3691 5.591  5.382  5.2524 5.6261 5.5651 5.3914 5.4652 5.3965 5.4007\n",
      " 5.1967 5.4036]\n",
      "Epoch:  36000\n",
      "Recall@10:  0.293\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.4609\n",
      "Val Loss:  [5.378  5.1856 5.4764 5.3092 5.6145 5.407  5.4413 5.3499 5.1968 5.444\n",
      " 5.1336 5.7947]\n",
      "Epoch:  36500\n",
      "Recall@10:  0.281\n",
      "NDCG:  0.128\n",
      "Train Loss:  4.4752\n",
      "Val Loss:  [5.57   5.5717 5.3123 5.2782 5.5575 5.2983 5.4744 5.3114 5.4902 5.4281\n",
      " 5.0723 5.6294]\n",
      "Epoch:  37000\n",
      "Recall@10:  0.288\n",
      "NDCG:  0.131\n",
      "Train Loss:  4.5241\n",
      "Val Loss:  [5.3934 5.2684 5.3429 5.2337 5.4237 5.3962 5.2713 5.3288 5.8967 5.5711\n",
      " 5.2137 5.5513]\n",
      "Epoch:  37500\n",
      "Recall@10:  0.292\n",
      "NDCG:  0.132\n",
      "Train Loss:  4.4827\n",
      "Val Loss:  [5.2698 5.1437 5.2327 5.5039 5.4055 5.4082 5.7655 5.3672 5.4632 5.4501\n",
      " 5.3435 5.5206]\n",
      "Epoch:  38000\n",
      "Recall@10:  0.287\n",
      "NDCG:  0.13\n",
      "Train Loss:  4.5586\n",
      "Val Loss:  [5.5723 5.2217 5.4878 5.4248 5.4059 5.3226 5.3722 5.4958 5.6453 5.4308\n",
      " 5.2699 5.5773]\n",
      "Epoch:  38500\n",
      "Recall@10:  0.292\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.4782\n",
      "Val Loss:  [5.3544 5.2821 5.5027 5.3251 5.4047 5.4077 5.4645 5.5206 5.608  5.3816\n",
      " 5.3023 5.3537]\n",
      "Epoch:  39000\n",
      "Recall@10:  0.289\n",
      "NDCG:  0.131\n",
      "Train Loss:  4.6405\n",
      "Val Loss:  [5.6434 5.5747 5.2285 5.3772 5.4444 5.4431 5.2669 5.4319 5.4981 5.2887\n",
      " 5.0806 5.4284]\n",
      "Epoch:  39500\n",
      "Recall@10:  0.282\n",
      "NDCG:  0.128\n",
      "Train Loss:  4.4753\n",
      "Val Loss:  [5.4197 5.494  5.3425 5.668  5.2356 5.1354 5.3228 5.5751 5.3082 5.5157\n",
      " 5.5387 5.4878]\n",
      "Epoch:  40000\n",
      "Recall@10:  0.289\n",
      "NDCG:  0.131\n",
      "Train Loss:  4.5994\n",
      "Val Loss:  [5.4863 5.1538 5.2494 5.6864 5.0784 5.3544 5.6838 5.409  5.387  5.6211\n",
      " 5.2631 5.4696]\n",
      "Epoch:  40500\n",
      "Recall@10:  0.29\n",
      "NDCG:  0.132\n",
      "Train Loss:  4.4999\n",
      "Val Loss:  [5.8596 5.3329 5.5049 5.4019 5.3725 5.476  5.3293 5.3886 5.1889 5.6775\n",
      " 5.3269 5.43  ]\n",
      "Epoch:  41000\n",
      "Recall@10:  0.287\n",
      "NDCG:  0.13\n",
      "Train Loss:  4.4243\n",
      "Val Loss:  [5.4671 5.3988 5.7147 5.3474 5.4916 5.3357 5.4936 5.3375 5.5366 5.2835\n",
      " 5.3171 5.5217]\n",
      "Epoch:  41500\n",
      "Recall@10:  0.295\n",
      "NDCG:  0.134\n",
      "Train Loss:  4.4077\n",
      "Val Loss:  [5.5445 5.4845 5.5451 5.8017 5.402  5.2909 5.197  5.1789 5.4807 5.1225\n",
      " 5.2658 5.236 ]\n",
      "Epoch:  42000\n",
      "Recall@10:  0.284\n",
      "NDCG:  0.129\n",
      "Train Loss:  4.4712\n",
      "Val Loss:  [5.3477 5.5324 5.4391 5.5246 5.2666 5.4599 5.3541 5.3821 5.562  5.0769\n",
      " 5.3129 5.6062]\n",
      "Epoch:  42500\n",
      "Recall@10:  0.291\n",
      "NDCG:  0.132\n",
      "Train Loss:  4.4898\n",
      "Val Loss:  [5.3626 5.189  5.3034 5.6104 5.2999 5.2173 5.3621 5.7956 5.4836 5.5282\n",
      " 5.2363 5.5531]\n",
      "Epoch:  43000\n",
      "Recall@10:  0.297\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.4248\n",
      "Val Loss:  [5.4831 5.4454 5.3696 5.2756 5.7927 5.6368 5.4377 5.4874 5.2055 4.8601\n",
      " 5.443  5.2618]\n",
      "Epoch:  43500\n",
      "Recall@10:  0.294\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.4277\n",
      "Val Loss:  [5.4535 5.5247 5.3402 5.405  5.5224 5.3042 5.2339 5.4426 5.6131 5.6142\n",
      " 5.454  5.0378]\n",
      "Epoch:  44000\n",
      "Recall@10:  0.295\n",
      "NDCG:  0.134\n",
      "Train Loss:  4.5105\n",
      "Val Loss:  [5.7908 5.4558 5.4648 5.3183 5.3814 5.2386 5.497  5.4273 5.4774 5.4524\n",
      " 5.1519 5.1506]\n",
      "Epoch:  44500\n",
      "Recall@10:  0.283\n",
      "NDCG:  0.129\n",
      "Train Loss:  4.5274\n",
      "Val Loss:  [5.3181 5.1742 5.414  5.3867 5.4705 5.4839 5.7318 5.5799 5.4209 5.4042\n",
      " 5.4324 5.1791]\n",
      "Epoch:  45000\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.5218\n",
      "Val Loss:  [5.5468 5.2879 5.2659 5.4925 5.2554 5.4263 5.2342 5.3875 5.2879 5.247\n",
      " 5.5026 5.502 ]\n",
      "Epoch:  45500\n",
      "Recall@10:  0.298\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.5118\n",
      "Val Loss:  [5.4795 5.1559 5.5739 5.2247 5.4116 5.5103 5.3871 5.3642 5.6121 5.3665\n",
      " 5.4128 5.2512]\n",
      "Epoch:  46000\n",
      "Recall@10:  0.282\n",
      "NDCG:  0.128\n",
      "Train Loss:  4.4466\n",
      "Val Loss:  [5.5731 5.4542 5.4045 5.3709 5.3542 5.5684 5.6795 5.3967 5.2448 5.4472\n",
      " 5.2907 5.3615]\n",
      "Epoch:  46500\n",
      "Recall@10:  0.309\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.5293\n",
      "Val Loss:  [5.3195 5.3877 5.324  5.3465 5.3207 5.3584 5.5888 5.5073 5.0561 5.3409\n",
      " 5.5232 5.3021]\n",
      "Epoch:  47000\n",
      "Recall@10:  0.296\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.4596\n",
      "Val Loss:  [5.3553 5.4372 5.2516 5.642  5.2402 5.1772 5.4452 5.6549 5.6193 5.2916\n",
      " 5.2519 5.526 ]\n",
      "Epoch:  47500\n",
      "Recall@10:  0.286\n",
      "NDCG:  0.13\n",
      "Train Loss:  4.4819\n",
      "Val Loss:  [5.2446 5.6048 5.1582 5.6632 5.4313 5.4845 5.2791 5.348  5.2829 5.341\n",
      " 5.3995 5.669 ]\n",
      "Epoch:  48000\n",
      "Recall@10:  0.297\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.5116\n",
      "Val Loss:  [5.2595 5.4527 5.1933 5.4625 5.5096 5.421  5.2471 5.49   5.408  5.3404\n",
      " 5.207  5.5494]\n",
      "Epoch:  48500\n",
      "Recall@10:  0.29\n",
      "NDCG:  0.132\n",
      "Train Loss:  4.475\n",
      "Val Loss:  [5.3645 5.4656 5.3131 5.2791 5.3198 5.6151 5.3043 5.4394 5.608  5.2041\n",
      " 5.5168 5.2993]\n",
      "Epoch:  49000\n",
      "Recall@10:  0.297\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.3846\n",
      "Val Loss:  [5.579  5.0904 5.3501 5.3402 5.35   5.3627 5.4885 5.2351 5.323  5.4728\n",
      " 5.4646 5.2467]\n",
      "Epoch:  49500\n",
      "Recall@10:  0.293\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.4231\n",
      "Val Loss:  [5.3161 5.3015 5.4464 5.3267 5.3265 5.3409 5.2899 5.8441 5.4664 5.4407\n",
      " 5.3576 5.4001]\n",
      "Epoch:  50000\n",
      "Recall@10:  0.304\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.5088\n",
      "Val Loss:  [5.198  5.5529 5.4315 5.3667 5.3353 5.2421 5.2825 5.2094 5.4907 5.5157\n",
      " 5.3388 5.3382]\n",
      "Epoch:  50500\n",
      "Recall@10:  0.3\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.4382\n",
      "Val Loss:  [5.2816 5.6341 5.1769 5.3176 5.4239 5.4664 5.4694 5.2497 5.1878 5.5832\n",
      " 5.4664 5.5023]\n",
      "Epoch:  51000\n",
      "Recall@10:  0.297\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.3395\n",
      "Val Loss:  [5.4375 5.4521 5.3337 5.5153 5.3075 5.326  5.4335 5.5064 5.1998 5.013\n",
      " 5.589  5.3225]\n",
      "Epoch:  51500\n",
      "Recall@10:  0.299\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.4131\n",
      "Val Loss:  [5.2838 5.2326 5.4636 5.2607 5.2599 5.3851 5.1645 5.3428 5.5924 5.606\n",
      " 5.258  5.3377]\n",
      "Epoch:  52000\n",
      "Recall@10:  0.305\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.4588\n",
      "Val Loss:  [5.1958 5.4127 5.4937 5.2173 5.4511 5.4176 5.5421 5.1941 5.1156 5.4576\n",
      " 5.711  5.2546]\n",
      "Epoch:  52500\n",
      "Recall@10:  0.294\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.4732\n",
      "Val Loss:  [5.4078 5.1487 5.4564 5.5    5.3573 5.2128 5.658  5.5318 5.2777 5.4456\n",
      " 5.5571 5.163 ]\n",
      "Epoch:  53000\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.4696\n",
      "Val Loss:  [5.4875 5.3209 5.4024 5.2001 5.5742 5.047  5.2968 5.2959 5.4641 5.2621\n",
      " 5.5617 5.247 ]\n",
      "Epoch:  53500\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4987\n",
      "Val Loss:  [5.269  5.5173 5.5042 5.2237 5.3378 5.2664 5.4469 5.191  5.2984 5.6708\n",
      " 5.3075 5.6676]\n",
      "Epoch:  54000\n",
      "Recall@10:  0.293\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.4118\n",
      "Val Loss:  [5.3314 5.6651 5.2043 5.5374 5.5792 5.1794 5.3543 5.4538 5.1366 5.4156\n",
      " 5.2191 5.4616]\n",
      "Epoch:  54500\n",
      "Recall@10:  0.307\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.5398\n",
      "Val Loss:  [5.5781 5.5178 5.1103 5.2298 5.4318 5.5501 5.4584 5.3857 5.4347 5.3782\n",
      " 5.0636 5.3922]\n",
      "Epoch:  55000\n",
      "Recall@10:  0.296\n",
      "NDCG:  0.134\n",
      "Train Loss:  4.3208\n",
      "Val Loss:  [5.3433 5.5265 5.5598 5.2589 5.4639 5.5443 5.3283 5.4159 5.3845 5.2836\n",
      " 5.5875 5.0959]\n",
      "Epoch:  55500\n",
      "Recall@10:  0.279\n",
      "NDCG:  0.127\n",
      "Train Loss:  4.469\n",
      "Val Loss:  [5.4888 5.3681 5.4016 5.4854 5.4807 5.4603 5.5612 5.4902 5.4218 5.2181\n",
      " 5.2513 5.4021]\n",
      "Epoch:  56000\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.5545\n",
      "Val Loss:  [5.2535 5.3288 5.3261 5.3472 5.3645 5.3972 5.6001 5.3228 5.406  5.3607\n",
      " 5.3529 5.4609]\n",
      "Epoch:  56500\n",
      "Recall@10:  0.306\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.4481\n",
      "Val Loss:  [5.2596 5.4024 5.4553 5.252  5.4855 5.4077 5.6171 5.2875 5.134  5.2714\n",
      " 5.4812 5.5677]\n",
      "Epoch:  58000\n",
      "Recall@10:  0.298\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.5074\n",
      "Val Loss:  [5.6703 5.1672 5.2158 5.2912 5.2232 5.355  5.5217 5.3151 5.5478 5.1671\n",
      " 5.6162 5.4108]\n",
      "Epoch:  58500\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4034\n",
      "Val Loss:  [5.3003 5.3228 5.3251 5.5784 5.3289 5.2494 5.4491 5.2504 5.3678 5.3647\n",
      " 5.6723 5.2166]\n",
      "Epoch:  59000\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.3725\n",
      "Val Loss:  [5.4355 5.4705 5.6941 5.4906 5.2273 5.3258 5.4831 4.9832 5.1335 5.2867\n",
      " 5.5536 5.4238]\n",
      "Epoch:  59500\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.4316\n",
      "Val Loss:  [5.3839 5.3774 5.301  5.0637 5.5833 5.5928 5.3687 5.4305 5.3209 5.159\n",
      " 5.4128 5.0986]\n",
      "Epoch:  60000\n",
      "Recall@10:  0.298\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.4615\n",
      "Val Loss:  [5.1071 5.4091 5.4334 5.4808 5.5885 5.3979 5.3082 4.9665 5.507  5.3338\n",
      " 5.4194 5.3886]\n",
      "Epoch:  60500\n",
      "Recall@10:  0.304\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.4643\n",
      "Val Loss:  [5.4686 5.6525 5.6098 5.4251 5.2791 5.4492 5.2326 5.2203 5.4788 5.1122\n",
      " 5.2238 5.3558]\n",
      "Epoch:  61000\n",
      "Recall@10:  0.299\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.4549\n",
      "Val Loss:  [5.4193 5.3494 5.2236 5.6257 5.5936 5.238  5.2256 5.2768 5.4959 5.3231\n",
      " 5.3557 5.3047]\n",
      "Epoch:  61500\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.3886\n",
      "Val Loss:  [5.3769 5.4835 5.4673 5.0716 4.9381 5.5328 5.4888 5.225  5.4792 5.1064\n",
      " 5.4968 5.6154]\n",
      "Epoch:  62000\n",
      "Recall@10:  0.293\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.4013\n",
      "Val Loss:  [5.7063 5.3131 5.6363 5.367  5.3534 5.1059 5.3097 5.4108 5.3504 5.0542\n",
      " 5.4978 5.2924]\n",
      "Epoch:  62500\n",
      "Recall@10:  0.298\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.3928\n",
      "Val Loss:  [5.1837 5.2529 5.401  5.5221 5.454  5.0997 5.6408 5.2877 5.3859 5.4555\n",
      " 5.3544 5.5018]\n",
      "Epoch:  63000\n",
      "Recall@10:  0.307\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.5238\n",
      "Val Loss:  [5.3803 5.45   5.2642 5.2221 5.4357 5.364  5.2981 5.3741 5.6493 5.3902\n",
      " 5.3202 5.4595]\n",
      "Epoch:  63500\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4555\n",
      "Val Loss:  [5.3409 5.4688 5.3776 5.3958 5.3476 5.4165 5.2667 5.2496 5.35   5.7498\n",
      " 5.3692 5.4145]\n",
      "Epoch:  64000\n",
      "Recall@10:  0.289\n",
      "NDCG:  0.131\n",
      "Train Loss:  4.5071\n",
      "Val Loss:  [5.4982 5.4776 5.4759 5.4056 5.4457 5.1188 5.4586 5.2284 5.3163 5.4814\n",
      " 5.2991 5.2654]\n",
      "Epoch:  64500\n",
      "Recall@10:  0.3\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.3306\n",
      "Val Loss:  [5.7263 5.3454 5.3761 5.1174 5.412  5.2794 5.654  5.4363 5.4307 5.4229\n",
      " 5.1837 5.3608]\n",
      "Epoch:  65000\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.3896\n",
      "Val Loss:  [5.2258 5.8108 5.2682 5.5315 5.3299 5.574  5.2854 5.4215 5.2647 5.3234\n",
      " 5.2671 5.1831]\n",
      "Epoch:  65500\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4149\n",
      "Val Loss:  [5.2544 5.401  5.0801 5.2991 5.451  5.4953 5.3513 5.234  5.4727 5.5396\n",
      " 5.2204 5.404 ]\n",
      "Epoch:  66000\n",
      "Recall@10:  0.296\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.464\n",
      "Val Loss:  [5.1426 5.5407 5.4276 5.3413 5.3029 5.5209 5.383  5.2483 5.1973 5.3941\n",
      " 5.3437 5.6023]\n",
      "Epoch:  66500\n",
      "Recall@10:  0.307\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.433\n",
      "Val Loss:  [5.4852 5.4297 5.2889 5.2075 5.0217 5.4097 5.3022 5.4498 5.641  5.2438\n",
      " 5.2838 5.4668]\n",
      "Epoch:  67000\n",
      "Recall@10:  0.308\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.2831\n",
      "Val Loss:  [5.5842 5.6003 5.4283 5.5368 5.5281 5.4928 5.1235 5.2939 5.3737 5.0507\n",
      " 5.0258 5.2952]\n",
      "Epoch:  67500\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.5319\n",
      "Val Loss:  [5.6667 5.2201 5.4333 5.5665 5.2523 5.4056 5.2594 5.219  5.5618 5.4314\n",
      " 5.1126 5.2499]\n",
      "Epoch:  68000\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4625\n",
      "Val Loss:  [5.4564 5.2533 5.2983 5.2851 5.4273 5.2648 5.2563 5.2911 5.2896 5.5114\n",
      " 5.2476 5.6446]\n",
      "Epoch:  68500\n",
      "Recall@10:  0.304\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.4248\n",
      "Val Loss:  [5.1023 5.2771 5.7113 5.1638 5.4027 5.4897 5.4821 5.4596 5.4738 5.2801\n",
      " 5.1649 5.4076]\n",
      "Epoch:  69000\n",
      "Recall@10:  0.305\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.488\n",
      "Val Loss:  [5.2272 5.2983 5.2634 5.4802 5.347  5.0192 5.4263 5.6145 5.3082 5.4768\n",
      " 5.3096 5.3914]\n",
      "Epoch:  69500\n",
      "Recall@10:  0.292\n",
      "NDCG:  0.133\n",
      "Train Loss:  4.5004\n",
      "Val Loss:  [5.5173 5.6474 5.2062 5.3938 5.2553 5.3352 5.3481 5.8855 5.2429 5.2801\n",
      " 5.4745 5.1169]\n",
      "Epoch:  70000\n",
      "Recall@10:  0.294\n",
      "NDCG:  0.134\n",
      "Train Loss:  4.4593\n",
      "Val Loss:  [5.2292 5.4536 5.3491 5.3854 5.4159 5.4352 5.114  5.4813 5.3145 5.4161\n",
      " 5.4414 5.3213]\n",
      "Epoch:  70500\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4052\n",
      "Val Loss:  [5.3362 5.5555 5.524  5.3279 5.2436 5.5595 5.1114 5.3443 5.2508 5.4765\n",
      " 5.4792 5.1882]\n",
      "Epoch:  71000\n",
      "Recall@10:  0.299\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.3525\n",
      "Val Loss:  [5.5707 5.238  5.3245 5.2476 5.2341 5.4232 5.2559 5.5209 5.2759 5.4096\n",
      " 5.6668 5.4078]\n",
      "Epoch:  71500\n",
      "Recall@10:  0.308\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.3622\n",
      "Val Loss:  [5.5758 5.3818 5.3057 5.3726 5.2856 5.2119 5.6438 5.0627 5.1152 5.5037\n",
      " 5.6179 5.1267]\n",
      "Epoch:  72000\n",
      "Recall@10:  0.299\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.4199\n",
      "Val Loss:  [5.3525 5.4059 5.5607 5.4016 5.2039 5.6569 5.3499 5.2656 5.2147 5.4184\n",
      " 5.4484 5.139 ]\n",
      "Epoch:  72500\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.3746\n",
      "Val Loss:  [5.119  5.4766 5.4294 5.3339 5.3535 5.3666 5.2979 5.4558 5.216  5.366\n",
      " 5.2242 5.3269]\n",
      "Epoch:  73000\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4894\n",
      "Val Loss:  [5.1635 5.484  5.3714 5.2123 5.4739 5.6368 5.1459 5.3728 5.2046 5.6367\n",
      " 5.3748 5.4259]\n",
      "Epoch:  73500\n",
      "Recall@10:  0.305\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.3907\n",
      "Val Loss:  [5.2788 5.1956 5.2903 5.2127 5.6251 5.5319 5.2438 5.4715 5.0688 5.5501\n",
      " 5.112  5.4409]\n",
      "Epoch:  74000\n",
      "Recall@10:  0.296\n",
      "NDCG:  0.135\n",
      "Train Loss:  4.4397\n",
      "Val Loss:  [5.4569 5.4304 5.4037 5.225  5.2608 5.3231 5.4041 5.2898 5.3883 5.0398\n",
      " 5.48   5.4605]\n",
      "Epoch:  74500\n",
      "Recall@10:  0.306\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.3075\n",
      "Val Loss:  [5.3559 5.4088 5.5241 5.1265 5.1968 5.5516 5.2135 5.4928 5.3329 5.4331\n",
      " 5.5935 5.1955]\n",
      "Epoch:  75000\n",
      "Recall@10:  0.299\n",
      "NDCG:  0.136\n",
      "Train Loss:  4.3697\n",
      "Val Loss:  [5.2259 5.3464 5.4314 5.2674 5.3322 5.4683 5.3382 5.2696 5.5668 5.6775\n",
      " 5.0271 5.3713]\n",
      "Epoch:  75500\n",
      "Recall@10:  0.317\n",
      "NDCG:  0.144\n",
      "Train Loss:  4.4279\n",
      "Val Loss:  [5.3537 5.2533 5.4031 5.5249 5.297  5.5944 5.2529 5.4395 5.4181 5.3683\n",
      " 5.0986 5.0597]\n",
      "Epoch:  76000\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4314\n",
      "Val Loss:  [5.5253 5.4379 5.4659 5.2938 5.1867 5.4609 5.4963 5.2903 5.2817 5.2359\n",
      " 5.4482 5.3274]\n",
      "Epoch:  76500\n",
      "Recall@10:  0.306\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.3683\n",
      "Val Loss:  [5.1913 5.1368 5.3692 5.5314 5.32   5.3902 5.6072 5.4008 5.3832 5.1963\n",
      " 5.3597 5.3682]\n",
      "Epoch:  77000\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.3946\n",
      "Val Loss:  [5.4241 5.5322 5.275  5.2355 5.0634 5.5816 5.5075 5.2427 5.6238 5.4148\n",
      " 5.216  5.2471]\n",
      "Epoch:  77500\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.416\n",
      "Val Loss:  [5.5657 5.4541 5.5256 5.1326 5.3282 5.4491 5.1195 5.3609 5.2504 5.1841\n",
      " 5.3164 5.4939]\n",
      "Epoch:  78000\n",
      "Recall@10:  0.307\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.3428\n",
      "Val Loss:  [5.6118 5.2389 5.3103 5.4241 5.2594 5.3454 5.4377 5.3001 5.2943 5.3559\n",
      " 5.7134 5.1459]\n",
      "Epoch:  78500\n",
      "Recall@10:  0.308\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.5052\n",
      "Val Loss:  [5.2474 5.4905 5.2408 5.3691 5.5662 5.0987 5.7188 4.9841 5.387  5.5269\n",
      " 5.347  5.4312]\n",
      "Epoch:  79000\n",
      "Recall@10:  0.311\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.4291\n",
      "Val Loss:  [5.3729 5.1525 5.3453 5.2251 5.1992 5.2546 5.5063 5.5211 5.3058 5.4034\n",
      " 5.4059 5.1086]\n",
      "Epoch:  79500\n",
      "Recall@10:  0.309\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.4087\n",
      "Val Loss:  [5.1643 5.4345 5.4043 5.5426 5.161  5.2103 5.4049 5.3685 5.2397 5.5564\n",
      " 5.26   5.6517]\n",
      "Epoch:  80000\n",
      "Recall@10:  0.304\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.4813\n",
      "Val Loss:  [5.2649 5.5203 5.352  5.3393 5.6466 5.1911 5.4615 5.0877 5.4652 5.467\n",
      " 5.1897 5.4926]\n",
      "Epoch:  80500\n",
      "Recall@10:  0.308\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.4091\n",
      "Val Loss:  [5.4603 5.3635 4.9994 5.2773 5.2974 5.2986 5.3676 5.4061 5.4275 5.4166\n",
      " 5.3348 5.209 ]\n",
      "Epoch:  81000\n",
      "Recall@10:  0.307\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.5149\n",
      "Val Loss:  [5.2651 5.5185 5.4572 5.4841 5.3757 5.0734 5.504  5.144  5.3994 5.1966\n",
      " 5.5683 4.9865]\n",
      "Epoch:  81500\n",
      "Recall@10:  0.301\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.3643\n",
      "Val Loss:  [5.5043 5.2965 5.1741 5.2656 5.2075 5.1665 5.327  5.5925 5.4592 5.2747\n",
      " 5.5539 5.3374]\n",
      "Epoch:  82000\n",
      "Recall@10:  0.307\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.4145\n",
      "Val Loss:  [5.3842 5.3001 5.4085 5.4257 5.5827 5.0258 5.3463 5.7348 5.4421 5.4545\n",
      " 5.0767 5.1086]\n",
      "Epoch:  82500\n",
      "Recall@10:  0.304\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.3049\n",
      "Val Loss:  [5.369  5.2326 5.5558 5.5508 5.34   5.3889 5.3252 5.2768 5.3381 5.4705\n",
      " 5.0411 5.3661]\n",
      "Epoch:  83000\n",
      "Recall@10:  0.31\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.4148\n",
      "Val Loss:  [5.456  5.3249 5.4802 5.1763 5.4477 5.588  5.3382 5.4637 5.3443 5.4603\n",
      " 5.3751 5.2434]\n",
      "Epoch:  83500\n",
      "Recall@10:  0.315\n",
      "NDCG:  0.143\n",
      "Train Loss:  4.4136\n",
      "Val Loss:  [5.1765 5.4354 5.3389 5.2483 5.3359 5.416  5.4208 5.1986 5.2953 5.5817\n",
      " 5.3574 5.0454]\n",
      "Epoch:  84000\n",
      "Recall@10:  0.306\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.5143\n",
      "Val Loss:  [5.3161 5.4063 5.1551 5.3585 5.2459 5.1346 5.4773 5.4    5.6132 5.2484\n",
      " 5.5083 5.3465]\n",
      "Epoch:  84500\n",
      "Recall@10:  0.306\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.4436\n",
      "Val Loss:  [5.2115 5.4844 5.1798 5.4118 5.4214 5.3857 5.5249 5.3981 5.2691 5.1519\n",
      " 5.4548 5.3976]\n",
      "Epoch:  85000\n",
      "Recall@10:  0.313\n",
      "NDCG:  0.142\n",
      "Train Loss:  4.4111\n",
      "Val Loss:  [5.361  5.5895 5.1225 5.1563 5.3507 5.0764 5.3529 5.4168 5.5303 5.4404\n",
      " 5.2228 5.2559]\n",
      "Epoch:  85500\n",
      "Recall@10:  0.308\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.4206\n",
      "Val Loss:  [5.5796 5.4515 5.1294 5.4851 5.0733 5.068  5.3109 5.806  5.2952 5.2626\n",
      " 5.2474 5.1741]\n",
      "Epoch:  86000\n",
      "Recall@10:  0.31\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.4101\n",
      "Val Loss:  [5.2791 5.4008 5.4723 5.499  5.2144 5.1348 5.2511 5.4102 5.4114 5.422\n",
      " 5.1891 5.3357]\n",
      "Epoch:  87500\n",
      "Recall@10:  0.305\n",
      "NDCG:  0.139\n",
      "Train Loss:  4.3402\n",
      "Val Loss:  [5.425  5.1989 5.4223 5.2787 5.2409 5.599  5.5622 5.1298 5.7075 5.2584\n",
      " 5.2219 5.157 ]\n",
      "Epoch:  88000\n",
      "Recall@10:  0.315\n",
      "NDCG:  0.143\n",
      "Train Loss:  4.4033\n",
      "Val Loss:  [5.5616 5.3503 5.2429 5.3    5.3136 5.4882 5.2451 5.4921 5.1676 5.1976\n",
      " 5.3195 5.1987]\n",
      "Epoch:  88500\n",
      "Recall@10:  0.313\n",
      "NDCG:  0.142\n",
      "Train Loss:  4.4244\n",
      "Val Loss:  [5.4424 5.102  5.3215 5.2827 5.6703 5.6724 5.2264 5.4497 5.1171 5.4119\n",
      " 5.1059 5.1967]\n",
      "Epoch:  89000\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4634\n",
      "Val Loss:  [5.4686 5.1919 5.4631 5.1817 5.455  5.557  5.5109 5.3785 5.4518 5.2014\n",
      " 5.0993 5.4842]\n",
      "Epoch:  89500\n",
      "Recall@10:  0.307\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.4849\n",
      "Val Loss:  [5.1064 5.2891 5.4532 5.2465 5.2186 5.5343 5.3909 5.4038 5.3356 5.4598\n",
      " 5.1998 5.5355]\n",
      "Epoch:  90000\n",
      "Recall@10:  0.308\n",
      "NDCG:  0.14\n",
      "Train Loss:  4.3457\n",
      "Val Loss:  [5.1869 5.3367 5.4079 5.2724 5.3793 5.1664 5.2123 5.5982 5.1675 5.2999\n",
      " 5.4005 5.3182]\n",
      "Epoch:  90500\n",
      "Recall@10:  0.314\n",
      "NDCG:  0.143\n",
      "Train Loss:  4.3634\n",
      "Val Loss:  [5.2317 5.2946 5.5819 5.2664 5.3311 5.3291 5.3497 5.4411 5.3227 5.3685\n",
      " 5.4383 5.3405]\n",
      "Epoch:  91000\n",
      "Recall@10:  0.31\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.5247\n",
      "Val Loss:  [5.3121 5.473  5.1333 5.2955 5.1472 5.5126 5.4986 5.4053 5.421  5.4595\n",
      " 5.2252 5.4212]\n",
      "Epoch:  91500\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4438\n",
      "Val Loss:  [5.2577 5.3589 5.2554 5.1595 5.6274 5.5316 5.4219 5.3932 5.3209 5.1799\n",
      " 5.6694 5.2618]\n",
      "Epoch:  92000\n",
      "Recall@10:  0.311\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.4235\n",
      "Val Loss:  [5.5506 5.3264 5.5366 5.2835 5.3361 5.0742 5.3637 4.9597 5.3115 5.5555\n",
      " 5.3625 5.6412]\n",
      "Epoch:  92500\n",
      "Recall@10:  0.326\n",
      "NDCG:  0.148\n",
      "Train Loss:  4.3548\n",
      "Val Loss:  [5.3942 5.3594 5.312  5.2212 5.3729 4.9276 5.376  5.297  5.4815 5.4587\n",
      " 5.3489 5.3637]\n",
      "Epoch:  93000\n",
      "Recall@10:  0.317\n",
      "NDCG:  0.144\n",
      "Train Loss:  4.4236\n",
      "Val Loss:  [5.2256 5.4808 5.6286 5.2683 5.4654 5.395  5.0146 5.2775 5.1631 5.5806\n",
      " 5.1564 5.3474]\n",
      "Epoch:  93500\n",
      "Recall@10:  0.311\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.4293\n",
      "Val Loss:  [5.2951 5.3737 5.4116 5.3624 5.3176 5.5343 5.4331 5.172  5.3129 5.2917\n",
      " 5.3677 5.3855]\n",
      "Epoch:  94000\n",
      "Recall@10:  0.311\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.4151\n",
      "Val Loss:  [5.517  5.1099 5.4756 5.3877 5.0582 5.245  5.3348 5.556  5.2923 5.6133\n",
      " 5.3386 5.2016]\n",
      "Epoch:  94500\n",
      "Recall@10:  0.314\n",
      "NDCG:  0.143\n",
      "Train Loss:  4.3465\n",
      "Val Loss:  [5.4944 5.6826 5.308  5.139  5.2708 5.2251 5.5014 5.52   5.1989 5.1288\n",
      " 5.2435 5.2044]\n",
      "Epoch:  95000\n",
      "Recall@10:  0.31\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.2398\n",
      "Val Loss:  [5.5488 5.157  5.2794 5.5718 5.1342 5.4729 5.428  5.4092 5.1462 5.3267\n",
      " 5.3563 5.1656]\n",
      "Epoch:  95500\n",
      "Recall@10:  0.32\n",
      "NDCG:  0.145\n",
      "Train Loss:  4.3659\n",
      "Val Loss:  [5.3026 5.4821 5.1593 5.3403 5.4178 5.4411 5.3156 5.5044 5.3932 5.4072\n",
      " 5.0111 5.1207]\n",
      "Epoch:  96000\n",
      "Recall@10:  0.31\n",
      "NDCG:  0.141\n",
      "Train Loss:  4.3078\n",
      "Val Loss:  [5.497  5.3231 5.3348 5.1978 5.6726 5.536  5.1566 5.3227 5.1118 5.6462\n",
      " 5.3669 5.2479]\n",
      "Epoch:  96500\n",
      "Recall@10:  0.313\n",
      "NDCG:  0.142\n",
      "Train Loss:  4.3984\n",
      "Val Loss:  [5.202  5.2807 5.2389 5.2667 5.457  5.6286 5.1601 5.4459 5.3319 5.2447\n",
      " 5.3898 5.4341]\n",
      "Epoch:  97000\n",
      "Recall@10:  0.303\n",
      "NDCG:  0.138\n",
      "Train Loss:  4.4234\n",
      "Val Loss:  [5.5193 5.4444 5.434  5.5018 5.2071 5.5236 5.3819 5.4445 5.0387 5.376\n",
      " 5.41   5.1614]\n",
      "Epoch:  97500\n",
      "Recall@10:  0.315\n",
      "NDCG:  0.143\n",
      "Train Loss:  4.281\n",
      "Val Loss:  [5.3204 5.38   5.2671 5.3804 5.3451 5.3965 5.4063 5.3019 5.5387 5.4095\n",
      " 5.1873 5.1877]\n",
      "Epoch:  98000\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4496\n",
      "Val Loss:  [5.1515 5.2656 5.2731 5.3579 5.3787 5.2733 5.1833 5.1794 5.5037 5.4574\n",
      " 5.4166 5.8056]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m recall_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     20\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mTrainMaskedDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbernoulli(batch, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Create train\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m X \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create target\u001b[39;00m\n\u001b[1;32m     24\u001b[0m y \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m*\u001b[39m mask\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/lib/python3.9/site-packages/torch/_tensor.py:848\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VariableFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = TrainMaskedDataset(torch.tensor(list(train.values())), end_code)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "val_dataset = ValidMaskedDataset(torch.tensor(list(val.values())), end_code)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=end_code, reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 5000\n",
    "outputs = []\n",
    "losses = []\n",
    "\n",
    "counter = 0\n",
    "recall_list = []\n",
    "for epoch in range(epochs):\n",
    "    for X, y in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to('cuda:0')\n",
    "        y = y.to('cuda:0')\n",
    "\n",
    "        loss = loss_function(model.forward(X).view(-1, 3955), y.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "         \n",
    "        optimizer.step()\n",
    "        \n",
    "        counter += 1\n",
    "        if counter % 500 == 0:\n",
    "            val_losses = []\n",
    "            recall_batch = []\n",
    "            ndcg_batch = []\n",
    "            for X_val, y_val in val_loader:\n",
    "                \n",
    "                X_val = X_val.to('cuda:0')\n",
    "                y_val = y_val.to('cuda:0')\n",
    "                \n",
    "                y_pred = model.forward(X_val.long())[:, -1, :]\n",
    "                \n",
    "                val_loss = loss_function(y_pred.view(-1, 3955), y_val.long().view(-1))\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                recall_batch.append(recall_k(y_pred, y_val, k=10))\n",
    "#                 print(y_pred.shape)\n",
    "#                 print(y_val.shape)\n",
    "                ndcg_batch.append(ndcg_k(y_pred, y_val))\n",
    "\n",
    "#             print(counter, np.mean(recall_batch).round(3), np.round(loss.item(), 4), np.mean(val_losses).round(4))\n",
    "            print(\"Epoch: \", counter)\n",
    "            print(\"Recall@10: \", np.mean(recall_batch).round(3))\n",
    "            print(\"NDCG: \", np.mean(ndcg_batch).round(3))\n",
    "            print(\"Train Loss: \", np.round(loss.item(), 4))\n",
    "            print(\"Val Loss: \", np.round(val_losses, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "779e60af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  98318\n",
      "Recall@10:  0.302\n",
      "NDCG:  0.137\n",
      "Train Loss:  4.4358\n",
      "Val Loss:  [5.1515 5.2656 5.2731 5.3579 5.3787 5.2733 5.1833 5.1794 5.5037 5.4574\n",
      " 5.4166 5.8056 5.4431 5.3379 5.2369 5.3678 5.0715 5.4771 5.1553 5.3522\n",
      " 5.4999 5.376  5.2944 5.7084 5.584  5.377  5.3392 5.346  5.6916 5.3703\n",
      " 5.5946 5.1375 5.3139 5.4448 5.4744 5.5418 5.3784 5.3557 5.4725 5.6016\n",
      " 5.1977 5.3131 5.2406 5.5041 5.5196 5.7267 5.159  5.4073 5.3516 5.5976\n",
      " 5.5631 5.1783 5.4084 5.3012 5.5095 5.2314 5.3875 5.4784 5.245  5.11\n",
      " 5.4518 5.5841 5.323  5.3951 5.3579 5.4905 5.3038 5.4309 5.3803 5.538\n",
      " 5.4747 5.2859]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ValidMaskedDataset(torch.tensor(list(test.values())), end_code)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "recall_batch = []\n",
    "ndcg_batch = []\n",
    "for X_val, y_val in test_loader:\n",
    "\n",
    "    X_val = X_val.to('cuda:0')\n",
    "    y_val = y_val.to('cuda:0')\n",
    "\n",
    "    y_pred = model.forward(X_val.long())[:, -1, :]\n",
    "\n",
    "    val_loss = loss_function(y_pred.view(-1, 3955), y_val.long().view(-1))\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    recall_batch.append(recall_k(y_pred, y_val, k=10))\n",
    "#                 print(y_pred.shape)\n",
    "#                 print(y_val.shape)\n",
    "    ndcg_batch.append(ndcg_k(y_pred, y_val))\n",
    "\n",
    "#             print(counter, np.mean(recall_batch).round(3), np.round(loss.item(), 4), np.mean(val_losses).round(4))\n",
    "print(\"Epoch: \", counter)\n",
    "print(\"Recall@10: \", np.mean(recall_batch).round(3))\n",
    "print(\"NDCG: \", np.mean(ndcg_batch).round(3))\n",
    "print(\"Train Loss: \", np.round(loss.item(), 4))\n",
    "print(\"Val Loss: \", np.round(val_losses, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15000\n",
    "for epoch in range(epochs):\n",
    "    for X, y in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to('cuda:0')\n",
    "        y = y.to('cuda:0')\n",
    "\n",
    "        loss = loss_function(model.forward(X).view(-1, 3955), y.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "         \n",
    "        optimizer.step()\n",
    "        \n",
    "        counter += 1\n",
    "        if counter % 500 == 0:\n",
    "            val_losses = []\n",
    "            recall_batch = []\n",
    "            ndcg_batch = []\n",
    "            for X_val, y_val in val_loader:\n",
    "                \n",
    "                X_val = X_val.to('cuda:0')\n",
    "                y_val = y_val.to('cuda:0')\n",
    "                \n",
    "                y_pred = model.forward(X_val.long())[:, -1, :]\n",
    "                \n",
    "                val_loss = loss_function(y_pred.view(-1, 3955), y_val.long().view(-1))\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                recall_batch.append(recall_k(y_pred, y_val, k=10))\n",
    "#                 print(y_pred.shape)\n",
    "#                 print(y_val.shape)\n",
    "                ndcg_batch.append(ndcg_k(y_pred, y_val))\n",
    "\n",
    "#             print(counter, np.mean(recall_batch).round(3), np.round(loss.item(), 4), np.mean(val_losses).round(4))\n",
    "            print(\"Epoch: \", counter)\n",
    "            print(\"Recall@10: \", np.mean(recall_batch).round(3))\n",
    "            print(\"NDCG: \", np.mean(ndcg_batch).round(3))\n",
    "            print(\"Train Loss: \", np.round(loss.item(), 4))\n",
    "            print(\"Val Loss: \", np.round(val_losses, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
